{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Comprehend Custom Classification\n",
    "\n",
    "Quickly building a custom text classifier able to assign a specific label to a given text. This action is related to the NLP (Natural Language Processing) field. As we want to be fast, we are taking a shortcut. While we could have made a custom model in Sagemaker or using a best in class NLP classification models from the research community, we are going to leverage a high-level Machine Learning service from AWS: [Comprehend Custom Classification](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html). It allows to customize a NLP model able to label a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "The custom classifier workload is built in two steps:\n",
    "\n",
    "1. Training the custom model – no particular machine learning or deep learning knowledge is necessary\n",
    "2. Classifying new data\n",
    "\n",
    "Steps to follow are relatively simple:\n",
    "\n",
    "1. Create a bucket that will host training data\n",
    "2. Create a bucket that will host training data artifacts and production results. That can be the same\n",
    "3. Configure an IAM role allowing Comprehend to access newly created buckets\n",
    "4. Prepare data for training\n",
    "5. Upload training data in the S3 bucket\n",
    "6. Launch a “Train Classifier” job from the console: “Amazon Comprehend” > “Custom Classification” > “Train Classifier”\n",
    "7. Prepare data for classification (one text per line, no header, same format as training data). Some more details here\n",
    "8. Launch a custom classification job\n",
    "9. Gather results: a file name output.tar.gz is generated in the destination bucket. File format is JSON Line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, boto3, sagemaker\n",
    "from time import sleep\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 cp s3://fast-ai-nlp/yahoo_answers_csv.tgz ./yahoo_answers_csv.tgz\n",
    "gunzip yahoo_answers_csv.tgz\n",
    "tar xf yahoo_answers_csv.tar\n",
    "rm yahoo_answers_csv.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('yahoo_answers_csv/train.csv', error_bad_lines=False, header=None)\n",
    "df_test = pd.read_csv('yahoo_answers_csv/test.csv', error_bad_lines=False, header=None)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(n=1000000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train[1]+' '+df_train[2]+' '+df_train[3]\n",
    "df_train.drop([1,2,3], axis=1, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test[1]+' '+df_test[2]+' '+df_test[3]\n",
    "df_test.drop([1,2,3], axis=1, inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].str.replace(',', ' ')\n",
    "df_train['text'] = df_train['text'].str.replace('?', '')\n",
    "df_test['text'] = df_test['text'].str.replace(',', ' ')\n",
    "df_test['text'] = df_test['text'].str.replace('?', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('custom-train.csv', header=False, index=False, escapechar='\\\\', doublequote=False, quotechar='\"')\n",
    "df_test.to_csv('custom-test.csv', header=False, index=False, escapechar='\\\\', doublequote=False, quotechar='\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Upload the dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = session.upload_data('custom-train.csv', bucket, 'custom-classifier')\n",
    "test_path = session.upload_data('custom-test.csv', bucket, 'custom-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create the roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws iam create-role --role-name ComprehendBucketAccessRole --assume-role-policy-document file://ComprehendBucketAccessRole-TrustPolicy.json\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws iam put-role-policy --role-name ComprehendBucketAccessRole --policy-name BucketAccessPolicy --policy-document file://ComprehendBucketAccessRole-Permissions.json\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam')\n",
    "role = iam.get_role(RoleName='ComprehendBucketAccessRole')\n",
    "role['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.attach_role_policy(\n",
    "    RoleName=sagemaker.get_execution_role().split('/')[-1],\n",
    "    PolicyArn='arn:aws:iam::aws:policy/ComprehendFullAccess'\n",
    ")\n",
    "sleep(30) # wait 30 seconds to make sure IAM policies are applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_client = boto3.client('comprehend')\n",
    "response = comprehend_client.create_document_classifier(\n",
    "    DocumentClassifierName='yahoo-answers-custom-clf-demo',\n",
    "    DataAccessRoleArn=role['Role']['Arn'],\n",
    "    InputDataConfig={'S3Uri': train_path},\n",
    "    LanguageCode='en'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe_clf = comprehend_client.describe_document_classifier(DocumentClassifierArn=response['DocumentClassifierArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status = describe_clf['DocumentClassifierProperties']['Status']\n",
    "\n",
    "while (status == 'SUBMITTED') or (status == 'TRAINING'):\n",
    "    sleep(15)\n",
    "    describe_clf = comprehend_client.describe_document_classifier(DocumentClassifierArn=response['DocumentClassifierArn'])\n",
    "    status = describe_clf['DocumentClassifierProperties']['Status']\n",
    "    print(status)\n",
    "\n",
    "if status == 'IN_ERROR':\n",
    "    print(describe_clf['DocumentClassifierProperties']['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_client.describe_document_classifier(DocumentClassifierArn=response['DocumentClassifierArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Use the classifier for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_job = comprehend_client.start_document_classification_job(\n",
    "    JobName='yahoo-answers-custom-clf-inference-demo',\n",
    "    DocumentClassifierArn=response['DocumentClassifierArn'],\n",
    "    InputDataConfig={\n",
    "        'S3Uri': test_path,\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    OutputDataConfig={'S3Uri': 's3://'+bucket+'/custom-classifier/output/'},\n",
    "    DataAccessRoleArn=role['Role']['Arn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_clf_job = comprehend_client.describe_document_classification_job(JobId=clf_job['JobId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_job = describe_clf_job['DocumentClassificationJobProperties']['JobStatus']\n",
    "\n",
    "while (status_job == 'SUBMITTED') or (status_job == 'IN_PROGRESS'):\n",
    "    sleep(15)\n",
    "    describe_clf_job = comprehend_client.describe_document_classification_job(JobId=clf_job['JobId'])\n",
    "    status_job = describe_clf_job['DocumentClassificationJobProperties']['JobStatus']\n",
    "    print(status_job)\n",
    "\n",
    "if status_job == 'FAILED':\n",
    "    print(describe_clf_job['DocumentClassificationJobProperties']['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_client.describe_document_classification_job(JobId=clf_job['JobId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_s3 = boto3.client('s3')\n",
    "client_s3.download_file(bucket, \n",
    "                        describe_clf_job['DocumentClassificationJobProperties']['OutputDataConfig']['S3Uri'].split(bucket)[-1][1:],\n",
    "                        'output.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gunzip output.tar.gz\n",
    "tar xf output.tar\n",
    "rm output.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_json('predictions.jsonl', lines=True)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for i in range(0,len(df_test)):\n",
    "    y_pred += [int(predictions['Classes'][i][0]['Name'])]\n",
    "    y_true += [int(df_test[0].values[i])]\n",
    "    \n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_client.delete_document_classifier(DocumentClassifierArn=response['DocumentClassifierArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf yahoo_answers_csv\n",
    "rm custom-train.csv\n",
    "rm custom-test.csv\n",
    "rm predictions.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.detach_role_policy(\n",
    "    RoleName=sagemaker.get_execution_role().split('/')[-1],\n",
    "    PolicyArn='arn:aws:iam::aws:policy/ComprehendFullAccess'\n",
    ")\n",
    "sleep(5) # wait 5 seconds to make sure IAM policies are applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws iam delete-role-policy --role-name ComprehendBucketAccessRole --policy-name BucketAccessPolicy\n",
    "aws iam delete-role --role-name ComprehendBucketAccessRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm custom-train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm custom-test.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
